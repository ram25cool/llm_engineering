{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a98030af-fcd1-4d63-a36e-38ba053498fa",
   "metadata": {},
   "source": [
    "# A full business solution\n",
    "\n",
    "## Now we will take our project from Day 1 to the next level\n",
    "\n",
    "### BUSINESS CHALLENGE:\n",
    "\n",
    "Create a product that builds a Brochure for a company to be used for prospective clients, investors and potential recruits.\n",
    "\n",
    "We will be provided a company name and their primary website.\n",
    "\n",
    "See the end of this notebook for examples of real-world business applications.\n",
    "\n",
    "And remember: I'm always available if you have problems or ideas! Please do reach out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5b08506-dc8b-4443-9201-5f1848161363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "# If these fail, please check you're running from an 'activated' environment with (llms) in the command prompt\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc5d8880-f2ee-4c06-af16-ecbc0262af61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key looks good so far\n"
     ]
    }
   ],
   "source": [
    "# Initialize and constants\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "    \n",
    "MODEL = 'gpt-4o-mini'\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "106dd65e-90af-4ca8-86b6-23a41840645b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "    \"\"\"\n",
    "    A utility class to represent a Website that we have scraped, now with links\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        self.body = response.content\n",
    "        soup = BeautifulSoup(self.body, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        if soup.body:\n",
    "            for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                irrelevant.decompose()\n",
    "            self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        else:\n",
    "            self.text = \"\"\n",
    "        links = [link.get('href') for link in soup.find_all('a')]\n",
    "        self.links = [link for link in links if link]\n",
    "\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e30d8128-933b-44cc-81c8-ab4c9d86589a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://edwarddonner.com/',\n",
       " 'https://edwarddonner.com/connect-four/',\n",
       " 'https://edwarddonner.com/outsmart/',\n",
       " 'https://edwarddonner.com/about-me-and-about-nebula/',\n",
       " 'https://edwarddonner.com/posts/',\n",
       " 'https://edwarddonner.com/',\n",
       " 'https://news.ycombinator.com',\n",
       " 'https://nebula.io/?utm_source=ed&utm_medium=referral',\n",
       " 'https://www.prnewswire.com/news-releases/wynden-stark-group-acquires-nyc-venture-backed-tech-startup-untapt-301269512.html',\n",
       " 'https://patents.google.com/patent/US20210049536A1/',\n",
       " 'https://www.linkedin.com/in/eddonner/',\n",
       " 'https://edwarddonner.com/2025/05/28/connecting-my-courses-become-an-llm-expert-and-leader/',\n",
       " 'https://edwarddonner.com/2025/05/28/connecting-my-courses-become-an-llm-expert-and-leader/',\n",
       " 'https://edwarddonner.com/2025/05/18/2025-ai-executive-briefing/',\n",
       " 'https://edwarddonner.com/2025/05/18/2025-ai-executive-briefing/',\n",
       " 'https://edwarddonner.com/2025/04/21/the-complete-agentic-ai-engineering-course/',\n",
       " 'https://edwarddonner.com/2025/04/21/the-complete-agentic-ai-engineering-course/',\n",
       " 'https://edwarddonner.com/2025/01/23/llm-workshop-hands-on-with-agents-resources/',\n",
       " 'https://edwarddonner.com/2025/01/23/llm-workshop-hands-on-with-agents-resources/',\n",
       " 'https://edwarddonner.com/',\n",
       " 'https://edwarddonner.com/connect-four/',\n",
       " 'https://edwarddonner.com/outsmart/',\n",
       " 'https://edwarddonner.com/about-me-and-about-nebula/',\n",
       " 'https://edwarddonner.com/posts/',\n",
       " 'mailto:hello@mygroovydomain.com',\n",
       " 'https://www.linkedin.com/in/eddonner/',\n",
       " 'https://twitter.com/edwarddonner',\n",
       " 'https://www.facebook.com/edward.donner.52']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed = Website(\"https://edwarddonner.com\")\n",
    "ed.links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1771af9c-717a-4fca-bbbe-8a95893312c3",
   "metadata": {},
   "source": [
    "## First step: Have GPT-4o-mini figure out which links are relevant\n",
    "\n",
    "### Use a call to gpt-4o-mini to read the links on a webpage, and respond in structured JSON.  \n",
    "It should decide which links are relevant, and replace relative links such as \"/about\" with \"https://company.com/about\".  \n",
    "We will use \"one shot prompting\" in which we provide an example of how it should respond in the prompt.\n",
    "\n",
    "This is an excellent use case for an LLM, because it requires nuanced understanding. Imagine trying to code this without LLMs by parsing and analyzing the webpage - it would be very hard!\n",
    "\n",
    "Sidenote: there is a more advanced technique called \"Structured Outputs\" in which we require the model to respond according to a spec. We cover this technique in Week 8 during our autonomous Agentic AI project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6957b079-0d96-45f7-a26a-3487510e9b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_system_prompt = \"You are provided with a list of links found on a webpage. \\\n",
    "You are able to decide which of the links would be most relevant to include in a brochure about the company, \\\n",
    "such as links to an About page, or a Company page, or Careers/Jobs pages.\\n\"\n",
    "link_system_prompt += \"You should respond in JSON as in this example:\"\n",
    "link_system_prompt += \"\"\"\n",
    "{\n",
    "    \"links\": [\n",
    "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
    "        {\"type\": \"careers page\", \"url\": \"https://another.full.url/careers\"}\n",
    "    ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b97e4068-97ed-4120-beae-c42105e4d59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are provided with a list of links found on a webpage. You are able to decide which of the links would be most relevant to include in a brochure about the company, such as links to an About page, or a Company page, or Careers/Jobs pages.\n",
      "You should respond in JSON as in this example:\n",
      "{\n",
      "    \"links\": [\n",
      "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
      "        {\"type\": \"careers page\": \"url\": \"https://another.full.url/careers\"}\n",
      "    ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(link_system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e1f601b-2eaf-499d-b6b8-c99050c9d6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links_user_prompt(website):\n",
    "    user_prompt = f\"Here is the list of links on the website of {website.url} - \"\n",
    "    user_prompt += \"please decide which of these are relevant web links for a brochure about the company, respond with the full https URL in JSON format. \\\n",
    "Do not include Terms of Service, Privacy, email links.\\n\"\n",
    "    user_prompt += \"Links (some might be relative links):\\n\"\n",
    "    user_prompt += \"\\n\".join(website.links)\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bcbfa78-6395-4685-b92c-22d592050fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the list of links on the website of https://edwarddonner.com - please decide which of these are relevant web links for a brochure about the company, respond with the full https URL in JSON format. Do not include Terms of Service, Privacy, email links.\n",
      "Links (some might be relative links):\n",
      "https://edwarddonner.com/\n",
      "https://edwarddonner.com/connect-four/\n",
      "https://edwarddonner.com/outsmart/\n",
      "https://edwarddonner.com/about-me-and-about-nebula/\n",
      "https://edwarddonner.com/posts/\n",
      "https://edwarddonner.com/\n",
      "https://news.ycombinator.com\n",
      "https://nebula.io/?utm_source=ed&utm_medium=referral\n",
      "https://www.prnewswire.com/news-releases/wynden-stark-group-acquires-nyc-venture-backed-tech-startup-untapt-301269512.html\n",
      "https://patents.google.com/patent/US20210049536A1/\n",
      "https://www.linkedin.com/in/eddonner/\n",
      "https://edwarddonner.com/2025/05/28/connecting-my-courses-become-an-llm-expert-and-leader/\n",
      "https://edwarddonner.com/2025/05/28/connecting-my-courses-become-an-llm-expert-and-leader/\n",
      "https://edwarddonner.com/2025/05/18/2025-ai-executive-briefing/\n",
      "https://edwarddonner.com/2025/05/18/2025-ai-executive-briefing/\n",
      "https://edwarddonner.com/2025/04/21/the-complete-agentic-ai-engineering-course/\n",
      "https://edwarddonner.com/2025/04/21/the-complete-agentic-ai-engineering-course/\n",
      "https://edwarddonner.com/2025/01/23/llm-workshop-hands-on-with-agents-resources/\n",
      "https://edwarddonner.com/2025/01/23/llm-workshop-hands-on-with-agents-resources/\n",
      "https://edwarddonner.com/\n",
      "https://edwarddonner.com/connect-four/\n",
      "https://edwarddonner.com/outsmart/\n",
      "https://edwarddonner.com/about-me-and-about-nebula/\n",
      "https://edwarddonner.com/posts/\n",
      "mailto:hello@mygroovydomain.com\n",
      "https://www.linkedin.com/in/eddonner/\n",
      "https://twitter.com/edwarddonner\n",
      "https://www.facebook.com/edward.donner.52\n"
     ]
    }
   ],
   "source": [
    "print(get_links_user_prompt(ed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a29aca19-ca13-471c-a4b4-5abbfa813f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(url):\n",
    "    website = Website(url)\n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": link_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_links_user_prompt(website)}\n",
    "      ],\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    return json.loads(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74a827a0-2782-4ae5-b210-4a242a8b4cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/',\n",
       " '/models',\n",
       " '/datasets',\n",
       " '/spaces',\n",
       " '/docs',\n",
       " '/enterprise',\n",
       " '/pricing',\n",
       " '/login',\n",
       " '/join',\n",
       " '/spaces',\n",
       " '/models',\n",
       " '/Qwen/Qwen-Image-Edit',\n",
       " '/deepseek-ai/DeepSeek-V3.1-Base',\n",
       " '/google/gemma-3-270m',\n",
       " '/tencent/Hunyuan-GameCraft-1.0',\n",
       " '/google/gemma-3-270m-it',\n",
       " '/models',\n",
       " '/spaces/enzostvs/deepsite',\n",
       " '/spaces/Qwen/Qwen-Image-Edit',\n",
       " '/spaces/zerogpu-aoti/wan2-2-fp8da-aoti-faster',\n",
       " '/spaces/AIDC-AI/Ovis2.5-9B',\n",
       " '/spaces/Qwen/Qwen-Image',\n",
       " '/spaces',\n",
       " '/datasets/fka/awesome-chatgpt-prompts',\n",
       " '/datasets/nvidia/Granary',\n",
       " '/datasets/nvidia/Llama-Nemotron-VLM-Dataset-v1',\n",
       " '/datasets/allenai/WildChat-4.8M',\n",
       " '/datasets/FreedomIntelligence/medical-o1-reasoning-SFT',\n",
       " '/datasets',\n",
       " '/join',\n",
       " '/pricing#endpoints',\n",
       " '/pricing#spaces',\n",
       " '/pricing',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/allenai',\n",
       " '/facebook',\n",
       " '/amazon',\n",
       " '/google',\n",
       " '/Intel',\n",
       " '/microsoft',\n",
       " '/grammarly',\n",
       " '/Writer',\n",
       " '/docs/transformers',\n",
       " '/docs/diffusers',\n",
       " '/docs/safetensors',\n",
       " '/docs/huggingface_hub',\n",
       " '/docs/tokenizers',\n",
       " '/docs/trl',\n",
       " '/docs/transformers.js',\n",
       " '/docs/smolagents',\n",
       " '/docs/peft',\n",
       " '/docs/datasets',\n",
       " '/docs/text-generation-inference',\n",
       " '/docs/accelerate',\n",
       " '/models',\n",
       " '/datasets',\n",
       " '/spaces',\n",
       " '/changelog',\n",
       " 'https://endpoints.huggingface.co',\n",
       " '/chat',\n",
       " '/huggingface',\n",
       " '/brand',\n",
       " '/terms-of-service',\n",
       " '/privacy',\n",
       " 'https://apply.workable.com/huggingface/',\n",
       " 'mailto:press@huggingface.co',\n",
       " '/learn',\n",
       " '/docs',\n",
       " '/blog',\n",
       " 'https://discuss.huggingface.co',\n",
       " 'https://status.huggingface.co/',\n",
       " 'https://github.com/huggingface',\n",
       " 'https://twitter.com/huggingface',\n",
       " 'https://www.linkedin.com/company/huggingface/',\n",
       " '/join/discord']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Anthropic has made their site harder to scrape, so I'm using HuggingFace..\n",
    "\n",
    "huggingface = Website(\"https://huggingface.co\")\n",
    "huggingface.links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3d583e2-dcc4-40cc-9b28-1e8dbf402924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'links': [{'type': 'about page', 'url': 'https://huggingface.co/'},\n",
       "  {'type': 'careers page', 'url': 'https://apply.workable.com/huggingface/'},\n",
       "  {'type': 'enterprise page', 'url': 'https://huggingface.co/enterprise'},\n",
       "  {'type': 'pricing page', 'url': 'https://huggingface.co/pricing'},\n",
       "  {'type': 'blog page', 'url': 'https://huggingface.co/blog'},\n",
       "  {'type': 'documentation page', 'url': 'https://huggingface.co/docs'}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_links(\"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d74128e-dfb6-47ec-9549-288b621c838c",
   "metadata": {},
   "source": [
    "## Second step: make the brochure!\n",
    "\n",
    "Assemble all the details into another prompt to GPT4-o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85a5b6e2-e7ef-44a9-bc7f-59ede71037b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_details(url):\n",
    "    result = \"Landing page:\\n\"\n",
    "    result += Website(url).get_contents()\n",
    "    links = get_links(url)\n",
    "    print(\"Found links:\", links)\n",
    "    for link in links[\"links\"]:\n",
    "        result += f\"\\n\\n{link['type']}\\n\"\n",
    "        result += Website(link[\"url\"]).get_contents()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5099bd14-076d-4745-baf3-dac08d8e5ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links: {'links': [{'type': 'about page', 'url': 'https://huggingface.co/huggingface'}, {'type': 'careers page', 'url': 'https://apply.workable.com/huggingface/'}, {'type': 'company page', 'url': 'https://huggingface.co/enterprise'}, {'type': 'pricing page', 'url': 'https://huggingface.co/pricing'}, {'type': 'blog page', 'url': 'https://huggingface.co/blog'}, {'type': 'documentation page', 'url': 'https://huggingface.co/docs'}]}\n",
      "Landing page:\n",
      "Webpage Title:\n",
      "Hugging Face – The AI community building the future.\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "The AI community building the future.\n",
      "The platform where the machine learning community collaborates on models, datasets, and applications.\n",
      "Explore AI Apps\n",
      "or\n",
      "Browse 1M+ models\n",
      "Trending on\n",
      "this week\n",
      "Models\n",
      "Qwen/Qwen-Image-Edit\n",
      "Updated\n",
      "3 days ago\n",
      "•\n",
      "16.8k\n",
      "•\n",
      "932\n",
      "deepseek-ai/DeepSeek-V3.1-Base\n",
      "Updated\n",
      "about 10 hours ago\n",
      "•\n",
      "5.68k\n",
      "•\n",
      "779\n",
      "google/gemma-3-270m\n",
      "Updated\n",
      "7 days ago\n",
      "•\n",
      "49.1k\n",
      "•\n",
      "549\n",
      "tencent/Hunyuan-GameCraft-1.0\n",
      "Updated\n",
      "2 days ago\n",
      "•\n",
      "74\n",
      "•\n",
      "440\n",
      "google/gemma-3-270m-it\n",
      "Updated\n",
      "7 days ago\n",
      "•\n",
      "67.9k\n",
      "•\n",
      "311\n",
      "Browse 1M+ models\n",
      "Spaces\n",
      "Running\n",
      "12.1k\n",
      "12.1k\n",
      "DeepSite v2\n",
      "🐳\n",
      "Generate any application with DeepSeek\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "208\n",
      "208\n",
      "Qwen Image Edit\n",
      "✒\n",
      "Edit images based on user instructions\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "MCP\n",
      "263\n",
      "263\n",
      "Wan2.2 14B Fast\n",
      "🎥\n",
      "generate a video from an image with a text prompt\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "150\n",
      "150\n",
      "Ovis2.5 9B\n",
      "📊\n",
      "High-accuracy vision & reasoning for complex tasks\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "692\n",
      "692\n",
      "Qwen Image\n",
      "🖼\n",
      "Generate images from text prompts\n",
      "Browse 400k+ applications\n",
      "Datasets\n",
      "fka/awesome-chatgpt-prompts\n",
      "Updated\n",
      "Jan 6\n",
      "•\n",
      "37.1k\n",
      "•\n",
      "8.79k\n",
      "nvidia/Granary\n",
      "Updated\n",
      "7 days ago\n",
      "•\n",
      "9.67k\n",
      "•\n",
      "100\n",
      "nvidia/Llama-Nemotron-VLM-Dataset-v1\n",
      "Updated\n",
      "2 days ago\n",
      "•\n",
      "2.97k\n",
      "•\n",
      "111\n",
      "allenai/WildChat-4.8M\n",
      "Updated\n",
      "10 days ago\n",
      "•\n",
      "2.68k\n",
      "•\n",
      "85\n",
      "FreedomIntelligence/medical-o1-reasoning-SFT\n",
      "Updated\n",
      "Apr 22\n",
      "•\n",
      "14.2k\n",
      "•\n",
      "845\n",
      "Browse 250k+ datasets\n",
      "The Home of Machine Learning\n",
      "Create, discover and collaborate on ML better.\n",
      "The collaboration platform\n",
      "Host and collaborate on unlimited public models, datasets and applications.\n",
      "Move faster\n",
      "With the HF Open source stack.\n",
      "Explore all modalities\n",
      "Text, image, video, audio or even 3D.\n",
      "Build your portfolio\n",
      "Share your work with the world and build your ML profile.\n",
      "Sign Up\n",
      "Accelerate your ML\n",
      "We provide paid Compute and Enterprise solutions.\n",
      "Compute\n",
      "Deploy on optimized\n",
      "Inference Endpoints\n",
      "or update your\n",
      "Spaces applications\n",
      "to a GPU in a few clicks.\n",
      "View pricing\n",
      "Starting at $0.60/hour for GPU\n",
      "Team & Enterprise\n",
      "Give your team the most advanced platform to build AI with enterprise-grade security, access controls and\n",
      "\t\t\tdedicated support.\n",
      "Getting started\n",
      "Starting at $20/user/month\n",
      "Single Sign-On\n",
      "Regions\n",
      "Priority Support\n",
      "Audit Logs\n",
      "Resource Groups\n",
      "Private Datasets Viewer\n",
      "More than 50,000 organizations are using Hugging Face\n",
      "Ai2\n",
      "Enterprise\n",
      "non-profit\n",
      "•\n",
      "783 models\n",
      "•\n",
      "3.89k followers\n",
      "AI at Meta\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "2.22k models\n",
      "•\n",
      "7.36k followers\n",
      "Amazon\n",
      "company\n",
      "•\n",
      "20 models\n",
      "•\n",
      "3.37k followers\n",
      "Google\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "1.04k models\n",
      "•\n",
      "25.5k followers\n",
      "Intel\n",
      "company\n",
      "•\n",
      "239 models\n",
      "•\n",
      "2.91k followers\n",
      "Microsoft\n",
      "company\n",
      "•\n",
      "419 models\n",
      "•\n",
      "14.3k followers\n",
      "Grammarly\n",
      "Team\n",
      "company\n",
      "•\n",
      "11 models\n",
      "•\n",
      "173 followers\n",
      "Writer\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "21 models\n",
      "•\n",
      "323 followers\n",
      "Our Open Source\n",
      "We are building the foundation of ML tooling with the community.\n",
      "Transformers\n",
      "148,598\n",
      "State-of-the-art AI models for PyTorch\n",
      "Diffusers\n",
      "30,410\n",
      "State-of-the-art Diffusion models in PyTorch\n",
      "Safetensors\n",
      "3,408\n",
      "Safe way to store/distribute neural network weights\n",
      "Hub Python Library\n",
      "2,858\n",
      "Python client to interact with the Hugging Face Hub\n",
      "Tokenizers\n",
      "10,008\n",
      "Fast tokenizers optimized for research & production\n",
      "TRL\n",
      "15,189\n",
      "Train transformers LMs with reinforcement learning\n",
      "Transformers.js\n",
      "14,386\n",
      "State-of-the-art ML running directly in your browser\n",
      "smolagents\n",
      "22,273\n",
      "Smol library to build great agents in Python\n",
      "PEFT\n",
      "19,363\n",
      "Parameter-efficient finetuning for large language models\n",
      "Datasets\n",
      "20,533\n",
      "Access & share datasets for any ML tasks\n",
      "Text Generation Inference\n",
      "10,440\n",
      "Serve language models with TGI optimized toolkit\n",
      "Accelerate\n",
      "9,057\n",
      "Train PyTorch models with multi-GPU, TPU, mixed precision\n",
      "System theme\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Changelog\n",
      "Inference Endpoints\n",
      "HuggingChat\n",
      "Company\n",
      "About\n",
      "Brand assets\n",
      "Terms of service\n",
      "Privacy\n",
      "Jobs\n",
      "Press\n",
      "Resources\n",
      "Learn\n",
      "Documentation\n",
      "Blog\n",
      "Forum\n",
      "Service Status\n",
      "Social\n",
      "GitHub\n",
      "Twitter\n",
      "LinkedIn\n",
      "Discord\n",
      "\n",
      "\n",
      "\n",
      "about page\n",
      "Webpage Title:\n",
      "huggingface (Hugging Face)\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Hugging Face\n",
      "Enterprise\n",
      "company\n",
      "Verified\n",
      "https://huggingface.co\n",
      "huggingface\n",
      "huggingface\n",
      "Activity Feed\n",
      "Follow\n",
      "55,064\n",
      "AI & ML interests\n",
      "The AI community building the future.\n",
      "Recent Activity\n",
      "lysandre\n",
      "updated\n",
      "a dataset\n",
      "about 6 hours ago\n",
      "huggingface/transformers-metadata\n",
      "eliebak\n",
      "new\n",
      "activity\n",
      "about 9 hours ago\n",
      "huggingface/InferenceSupport:\n",
      "deepseek-ai/DeepSeek-V3.1\n",
      "eliebak\n",
      "new\n",
      "activity\n",
      "about 18 hours ago\n",
      "huggingface/InferenceSupport:\n",
      "ByteDance-Seed/Seed-OSS-36B-Instruct\n",
      "View all activity\n",
      "Articles\n",
      "TimeScope: How Long Can Your Video Large Multimodal Model Go?\n",
      "30 days ago\n",
      "•\n",
      "38\n",
      "Yay! Organizations can now publish blog Articles\n",
      "Jan 20\n",
      "•\n",
      "48\n",
      "Team members\n",
      "210\n",
      "+176\n",
      "+163\n",
      "+142\n",
      "+132\n",
      "+112\n",
      "Organization Card\n",
      "Community\n",
      "About org cards\n",
      "👋 Hi!\n",
      "We are on a mission to democratize\n",
      "good\n",
      "machine learning, one commit at a time.\n",
      "If that sounds like something you should be doing, why don't you\n",
      "join us\n",
      "!\n",
      "For press enquiries, you can\n",
      "✉️ contact our team here\n",
      ".\n",
      "Collections\n",
      "1\n",
      "DistilBERT release\n",
      "Original DistilBERT model, checkpoints obtained from using teacher-student learning from the original BERT checkpoints.\n",
      "distilbert/distilbert-base-cased\n",
      "Fill-Mask\n",
      "•\n",
      "0.1B\n",
      "•\n",
      "Updated\n",
      "May 6, 2024\n",
      "•\n",
      "125k\n",
      "•\n",
      "•\n",
      "51\n",
      "distilbert/distilbert-base-uncased\n",
      "Fill-Mask\n",
      "•\n",
      "0.1B\n",
      "•\n",
      "Updated\n",
      "May 6, 2024\n",
      "•\n",
      "12.7M\n",
      "•\n",
      "•\n",
      "746\n",
      "distilbert/distilbert-base-multilingual-cased\n",
      "Fill-Mask\n",
      "•\n",
      "0.1B\n",
      "•\n",
      "Updated\n",
      "May 6, 2024\n",
      "•\n",
      "975k\n",
      "•\n",
      "209\n",
      "distilbert/distilbert-base-uncased-finetuned-sst-2-english\n",
      "Text Classification\n",
      "•\n",
      "0.1B\n",
      "•\n",
      "Updated\n",
      "Dec 19, 2023\n",
      "•\n",
      "2.86M\n",
      "•\n",
      "•\n",
      "811\n",
      "DistilBERT release\n",
      "Original DistilBERT model, checkpoints obtained from using teacher-student learning from the original BERT checkpoints.\n",
      "distilbert/distilbert-base-cased\n",
      "Fill-Mask\n",
      "•\n",
      "0.1B\n",
      "•\n",
      "Updated\n",
      "May 6, 2024\n",
      "•\n",
      "125k\n",
      "•\n",
      "•\n",
      "51\n",
      "distilbert/distilbert-base-uncased\n",
      "Fill-Mask\n",
      "•\n",
      "0.1B\n",
      "•\n",
      "Updated\n",
      "May 6, 2024\n",
      "•\n",
      "12.7M\n",
      "•\n",
      "•\n",
      "746\n",
      "distilbert/distilbert-base-multilingual-cased\n",
      "Fill-Mask\n",
      "•\n",
      "0.1B\n",
      "•\n",
      "Updated\n",
      "May 6, 2024\n",
      "•\n",
      "975k\n",
      "•\n",
      "209\n",
      "distilbert/distilbert-base-uncased-finetuned-sst-2-english\n",
      "Text Classification\n",
      "•\n",
      "0.1B\n",
      "•\n",
      "Updated\n",
      "Dec 19, 2023\n",
      "•\n",
      "2.86M\n",
      "•\n",
      "•\n",
      "811\n",
      "spaces\n",
      "30\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "pinned\n",
      "Running\n",
      "16\n",
      "Enterprise Hub\n",
      "🔒\n",
      "Why you need it, how to get it\n",
      "huggingface\n",
      "Jun 27\n",
      "pinned\n",
      "Running\n",
      "on\n",
      "CPU Upgrade\n",
      "15\n",
      "Hugging Face Fast\n",
      "🏎\n",
      "Test Hugging Face bandwidth\n",
      "huggingface\n",
      "Jun 12\n",
      "pinned\n",
      "Running\n",
      "99\n",
      "Number Tokenization Blog\n",
      "📈\n",
      "Explore how tokenization affects arithmetic in LLMs\n",
      "huggingface\n",
      "Dec 14, 2024\n",
      "Running\n",
      "462\n",
      "AI Deadlines\n",
      "⚡\n",
      "Generate project deadlines\n",
      "huggingface\n",
      "about 23 hours ago\n",
      "Running\n",
      "on\n",
      "CPU Upgrade\n",
      "199\n",
      "Inference Playground\n",
      "🔋\n",
      "Set theme for Hugging Face Playground\n",
      "huggingface\n",
      "2 days ago\n",
      "Running\n",
      "on\n",
      "CPU Upgrade\n",
      "19\n",
      "Openapi\n",
      "🦀\n",
      "Hub API Documentation\n",
      "huggingface\n",
      "Jun 18\n",
      "View 30\n",
      "\t\t\t\t\t\t\tSpaces\n",
      "models\n",
      "16\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "huggingface/time-series-transformer-tourism-monthly\n",
      "Time Series Forecasting\n",
      "•\n",
      "0.0B\n",
      "•\n",
      "Updated\n",
      "May 24\n",
      "•\n",
      "2.97k\n",
      "•\n",
      "22\n",
      "huggingface/timesfm-tourism-monthly\n",
      "0.0B\n",
      "•\n",
      "Updated\n",
      "Mar 31\n",
      "•\n",
      "11\n",
      "•\n",
      "2\n",
      "huggingface/CodeBERTa-language-id\n",
      "Text Classification\n",
      "•\n",
      "Updated\n",
      "Mar 29, 2024\n",
      "•\n",
      "1.16k\n",
      "•\n",
      "•\n",
      "63\n",
      "huggingface/falcon-40b-gptq\n",
      "Text Generation\n",
      "•\n",
      "7B\n",
      "•\n",
      "Updated\n",
      "Jun 14, 2023\n",
      "•\n",
      "51\n",
      "•\n",
      "13\n",
      "huggingface/autoformer-tourism-monthly\n",
      "Updated\n",
      "May 24, 2023\n",
      "•\n",
      "2.16k\n",
      "•\n",
      "10\n",
      "huggingface/distilbert-base-uncased-finetuned-mnli\n",
      "Text Classification\n",
      "•\n",
      "0.1B\n",
      "•\n",
      "Updated\n",
      "Mar 22, 2023\n",
      "•\n",
      "409\n",
      "•\n",
      "2\n",
      "huggingface/informer-tourism-monthly\n",
      "Updated\n",
      "Feb 24, 2023\n",
      "•\n",
      "2.32k\n",
      "•\n",
      "6\n",
      "huggingface/the-no-branch-repo\n",
      "Text-to-Image\n",
      "•\n",
      "Updated\n",
      "Feb 10, 2023\n",
      "•\n",
      "22\n",
      "•\n",
      "6\n",
      "huggingface/CodeBERTa-small-v1\n",
      "Fill-Mask\n",
      "•\n",
      "Updated\n",
      "Jun 27, 2022\n",
      "•\n",
      "64.3k\n",
      "•\n",
      "•\n",
      "84\n",
      "huggingface/test-model-repo\n",
      "Updated\n",
      "Nov 19, 2021\n",
      "•\n",
      "2\n",
      "View 16\n",
      "\t\t\t\t\t\t\tmodels\n",
      "datasets\n",
      "34\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "huggingface/transformers-metadata\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "about 6 hours ago\n",
      "•\n",
      "1.83k\n",
      "•\n",
      "1.15k\n",
      "•\n",
      "27\n",
      "huggingface/documentation-images\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "1 day ago\n",
      "•\n",
      "55\n",
      "•\n",
      "2.7M\n",
      "•\n",
      "78\n",
      "huggingface/diffusers-metadata\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "1 day ago\n",
      "•\n",
      "72\n",
      "•\n",
      "1.02k\n",
      "•\n",
      "8\n",
      "huggingface/policy-docs\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Jul 19\n",
      "•\n",
      "26\n",
      "•\n",
      "3.29k\n",
      "•\n",
      "13\n",
      "huggingface/badges\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Jul 17\n",
      "•\n",
      "1\n",
      "•\n",
      "830k\n",
      "•\n",
      "46\n",
      "huggingface/cats-image\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Jun 20\n",
      "•\n",
      "1\n",
      "•\n",
      "12.4k\n",
      "•\n",
      "2\n",
      "huggingface/label-files\n",
      "Updated\n",
      "Jun 12\n",
      "•\n",
      "2.19k\n",
      "•\n",
      "19\n",
      "huggingface/electricity-production\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "May 22\n",
      "•\n",
      "397\n",
      "•\n",
      "62\n",
      "•\n",
      "1\n",
      "huggingface/gemini-results-new-cs-papers-2025-02-11-100-230-updated\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Feb 17\n",
      "•\n",
      "130\n",
      "•\n",
      "87\n",
      "huggingface/wiki_dpr\n",
      "Updated\n",
      "Feb 5\n",
      "•\n",
      "265\n",
      "View 34\n",
      "\t\t\t\t\t\t\tdatasets\n",
      "System theme\n",
      "Company\n",
      "TOS\n",
      "Privacy\n",
      "About\n",
      "Jobs\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Pricing\n",
      "Docs\n",
      "\n",
      "\n",
      "\n",
      "careers page\n",
      "Webpage Title:\n",
      "Hugging Face - Current Openings\n",
      "Webpage Contents:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "company page\n",
      "Webpage Title:\n",
      "Enterprise Hub - Hugging Face\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Team & Enterprise Hub\n",
      "Scale your organization with the world’s leading AI platform\n",
      "Subscribe to\n",
      "Team\n",
      "starting at $20/user/month\n",
      "or\n",
      "Contact sales for\n",
      "Enterprise\n",
      "to explore flexible contract options\n",
      "Give your organization the most advanced platform to build AI with enterprise-grade security, access controls,\n",
      "\t\t\tdedicated support and more.\n",
      "Single Sign-On\n",
      "Connect securely to your identity provider with SSO integration.\n",
      "Regions\n",
      "Select, manage, and audit the location of your repository data.\n",
      "Audit Logs\n",
      "Stay in control with comprehensive logs that report on actions taken.\n",
      "Resource Groups\n",
      "Accurately manage access to repositories with granular access control.\n",
      "Token Management\n",
      "Centralized token control and custom approval policies for organization access.\n",
      "Analytics\n",
      "Track and analyze repository usage data in a single dashboard.\n",
      "Advanced Compute Options\n",
      "Increase scalability and performance with more compute options like ZeroGPU.\n",
      "ZeroGPU Quota Boost\n",
      "All organization members get 5x more ZeroGPU quota to get the most of Spaces.\n",
      "Private Datasets Viewer\n",
      "Enable the Dataset Viewer on your private datasets for easier collaboration.\n",
      "Private Storage\n",
      "Get an additional 1 TB of private storage for each member of your organization (then $25/month per extra TB).\n",
      "Inference Providers\n",
      "Enable organization billing for Inference Providers, monitor usage with analytics, and manage spending limits.\n",
      "Advanced security\n",
      "Configure organization-wide security policies and default repository visibility.\n",
      "Billing\n",
      "Control your budget effectively with managed billing and yearly commit options.\n",
      "Priority Support\n",
      "Maximize your platform usage with priority support from the Hugging Face team.\n",
      "Join the most forward-thinking AI organizations\n",
      "Everything you already know and love about Hugging Face in Enterprise mode.\n",
      "Subscribe to\n",
      "Team\n",
      "starting at $20/user/month\n",
      "or\n",
      "Contact sales for\n",
      "Enterprise\n",
      "to explore flexible contract options\n",
      "Google\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "1.04k models\n",
      "•\n",
      "25.5k followers\n",
      "Shopify\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "517 followers\n",
      "AMD\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "165 models\n",
      "•\n",
      "1.83k followers\n",
      "JetBrains\n",
      "Team\n",
      "company\n",
      "•\n",
      "13 models\n",
      "•\n",
      "666 followers\n",
      "Writer\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "21 models\n",
      "•\n",
      "323 followers\n",
      "ServiceNow\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "2 models\n",
      "•\n",
      "538 followers\n",
      "OpenAI\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "35 models\n",
      "•\n",
      "18k followers\n",
      "Toyota Research Institute\n",
      "Team\n",
      "company\n",
      "•\n",
      "10 models\n",
      "•\n",
      "137 followers\n",
      "Jusbrasil\n",
      "Team\n",
      "company\n",
      "•\n",
      "103 followers\n",
      "BAIDU\n",
      "Team\n",
      "company\n",
      "•\n",
      "25 models\n",
      "•\n",
      "955 followers\n",
      "Aledade Inc\n",
      "Enterprise\n",
      "+\n",
      "company\n",
      "•\n",
      "72 followers\n",
      "Grammarly\n",
      "Team\n",
      "company\n",
      "•\n",
      "11 models\n",
      "•\n",
      "173 followers\n",
      "MiniMax\n",
      "Team\n",
      "company\n",
      "•\n",
      "10 models\n",
      "•\n",
      "1.68k followers\n",
      "Liquid AI\n",
      "Team\n",
      "company\n",
      "•\n",
      "11 models\n",
      "•\n",
      "613 followers\n",
      "NVIDIA\n",
      "Enterprise\n",
      "+\n",
      "company\n",
      "•\n",
      "481 models\n",
      "•\n",
      "35.4k followers\n",
      "AI at Meta\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "2.22k models\n",
      "•\n",
      "7.36k followers\n",
      "Orange\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "7 models\n",
      "•\n",
      "265 followers\n",
      "Arm\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "1 model\n",
      "•\n",
      "261 followers\n",
      "Together\n",
      "Team\n",
      "company\n",
      "•\n",
      "33 models\n",
      "•\n",
      "672 followers\n",
      "Xsolla\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "157 followers\n",
      "ServiceNow-AI\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "4 models\n",
      "•\n",
      "317 followers\n",
      "Deutsche Telekom AG\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "7 models\n",
      "•\n",
      "168 followers\n",
      "IBM Granite\n",
      "Team\n",
      "company\n",
      "•\n",
      "133 models\n",
      "•\n",
      "2.24k followers\n",
      "creditkarma\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "77 followers\n",
      "StepFun\n",
      "Team\n",
      "company\n",
      "•\n",
      "22 models\n",
      "•\n",
      "1.31k followers\n",
      "Roblox Corporation\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "5 models\n",
      "•\n",
      "275 followers\n",
      "Novo Nordisk R&ED\n",
      "Team\n",
      "company\n",
      "•\n",
      "55 followers\n",
      "LinkedIn\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "74 followers\n",
      "Meta Llama\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "70 models\n",
      "•\n",
      "57.9k followers\n",
      "Nerdy Face\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "1 model\n",
      "•\n",
      "312 followers\n",
      "Snowflake\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "25 models\n",
      "•\n",
      "587 followers\n",
      "Tenstorrent Inc.\n",
      "Team\n",
      "company\n",
      "•\n",
      "222 followers\n",
      "Qwen\n",
      "Team\n",
      "company\n",
      "•\n",
      "339 models\n",
      "•\n",
      "45.3k followers\n",
      "PaloAltoNetworks\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "194 followers\n",
      "Nutanix\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "262 models\n",
      "•\n",
      "129 followers\n",
      "TNG Technology Consulting GmbH\n",
      "Team\n",
      "company\n",
      "•\n",
      "5 models\n",
      "•\n",
      "273 followers\n",
      "FuriosaAI\n",
      "Team\n",
      "company\n",
      "•\n",
      "20 models\n",
      "•\n",
      "101 followers\n",
      "Technology Innovation Institute\n",
      "Team\n",
      "company\n",
      "•\n",
      "107 models\n",
      "•\n",
      "1.57k followers\n",
      "H2O.ai\n",
      "Team\n",
      "company\n",
      "•\n",
      "71 models\n",
      "•\n",
      "442 followers\n",
      "HyperCLOVA X\n",
      "Team\n",
      "company\n",
      "•\n",
      "4 models\n",
      "•\n",
      "493 followers\n",
      "HiddenLayer\n",
      "Team\n",
      "company\n",
      "•\n",
      "1 model\n",
      "•\n",
      "76 followers\n",
      "Robust Intelligence\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "73 followers\n",
      "Compliance & Certifications\n",
      "GDPR Compliant\n",
      "SOC 2 Type 2\n",
      "System theme\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Changelog\n",
      "Inference Endpoints\n",
      "HuggingChat\n",
      "Company\n",
      "About\n",
      "Brand assets\n",
      "Terms of service\n",
      "Privacy\n",
      "Jobs\n",
      "Press\n",
      "Resources\n",
      "Learn\n",
      "Documentation\n",
      "Blog\n",
      "Forum\n",
      "Service Status\n",
      "Social\n",
      "GitHub\n",
      "Twitter\n",
      "LinkedIn\n",
      "Discord\n",
      "\n",
      "\n",
      "\n",
      "pricing page\n",
      "Webpage Title:\n",
      "Hugging Face – Pricing\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Pricing\n",
      "Leveling up AI collaboration and compute.\n",
      "Give your personal account or your organization the most advanced platform to build AI.\n",
      "PRO\n",
      "PRO Account\n",
      "Boost your personal HF experience\n",
      "Subscribe for\n",
      "$9\n",
      "per month\n",
      "Get PRO\n",
      "10× private storage capacity\n",
      "20× included inference credits\n",
      "8× ZeroGPU quota and highest queue priority\n",
      "Spaces Dev Mode & ZeroGPU Spaces hosting\n",
      "Publish blog articles on your HF profile\n",
      "Dataset Viewer for private datasets\n",
      "Show your support with a Pro badge\n",
      "Team\n",
      "Instant setup for growing teams\n",
      "Subscribe for\n",
      "$20\n",
      "per user per month\n",
      "Get Team (via credit card)\n",
      "SSO and SAML support\n",
      "Choose data location with Storage Regions\n",
      "Detailed action reviews with Audit Logs\n",
      "Granular access control via Resource Groups\n",
      "Repository usage Analytics\n",
      "Set auth policies and default repository visibility\n",
      "Centralized token control and approvals\n",
      "Dataset Viewer for private datasets\n",
      "Advanced compute options for Spaces\n",
      "All organization members get ZeroGPU and Inference Providers PRO benefits\n",
      "Enterprise\n",
      "Custom onboarding and enterprise features\n",
      "Starting at\n",
      "$50\n",
      "per user per month\n",
      "Contact Sales\n",
      "All benefits from the Team plan\n",
      "Managed billing with annual commitments\n",
      "Legal and Compliance processes\n",
      "Personalized support\n",
      "Need support to adopt the HF Hub in your organization? View our\n",
      "Expert Support\n",
      ".\n",
      "Hugging Face Hub\n",
      "free\n",
      "The HF Hub is the central place to explore, experiment, collaborate and build technology with Machine\n",
      "\t\t\t\t\tLearning.\n",
      "Join the open source Machine Learning movement!\n",
      "→\n",
      "Sign Up\n",
      "Create with ML\n",
      "Packed with ML features, like model eval, dataset viewer and much more.\n",
      "Collaborate\n",
      "Git based and designed for collaboration at its core.\n",
      "Play and learn\n",
      "Learn by experimenting and sharing with our awesome community.\n",
      "Build your ML portfolio\n",
      "Share your work with the world and build your own ML profile.\n",
      "Spaces Hardware\n",
      "Starting at $0\n",
      "Spaces are one of the most popular ways to share ML applications and demos with the world.\n",
      "Upgrade your Spaces with our selection of custom on-demand hardware:\n",
      "→\n",
      "Get started with Spaces\n",
      "Name\n",
      "CPU\n",
      "Memory\n",
      "Accelerator\n",
      "VRAM\n",
      "Hourly price\n",
      "CPU Basic\n",
      "2 vCPU\n",
      "16 GB\n",
      "-\n",
      "-\n",
      "FREE\n",
      "CPU Upgrade\n",
      "8 vCPU\n",
      "32 GB\n",
      "-\n",
      "-\n",
      "$0.03\n",
      "Nvidia T4 - small\n",
      "4 vCPU\n",
      "15 GB\n",
      "Nvidia T4\n",
      "16 GB\n",
      "$0.40\n",
      "Nvidia T4 - medium\n",
      "8 vCPU\n",
      "30 GB\n",
      "Nvidia T4\n",
      "16 GB\n",
      "$0.60\n",
      "1x Nvidia L4\n",
      "8 vCPU\n",
      "30 GB\n",
      "Nvidia L4\n",
      "24 GB\n",
      "$0.80\n",
      "4x Nvidia L4\n",
      "48 vCPU\n",
      "186 GB\n",
      "Nvidia L4\n",
      "96 GB\n",
      "$3.80\n",
      "1x Nvidia L40S\n",
      "8 vCPU\n",
      "62 GB\n",
      "Nvidia L4\n",
      "48 GB\n",
      "$1.80\n",
      "4x Nvidia L40S\n",
      "48 vCPU\n",
      "382 GB\n",
      "Nvidia L4\n",
      "192 GB\n",
      "$8.30\n",
      "8x Nvidia L40S\n",
      "192 vCPU\n",
      "1534 GB\n",
      "Nvidia L4\n",
      "384 GB\n",
      "$23.50\n",
      "Nvidia A10G - small\n",
      "4 vCPU\n",
      "15 GB\n",
      "Nvidia A10G\n",
      "24 GB\n",
      "$1.00\n",
      "Nvidia A10G - large\n",
      "12 vCPU\n",
      "46 GB\n",
      "Nvidia A10G\n",
      "24 GB\n",
      "$1.50\n",
      "2x Nvidia A10G - large\n",
      "24 vCPU\n",
      "92 GB\n",
      "Nvidia A10G\n",
      "48 GB\n",
      "$3.00\n",
      "4x Nvidia A10G - large\n",
      "48 vCPU\n",
      "184 GB\n",
      "Nvidia A10G\n",
      "96 GB\n",
      "$5.00\n",
      "Nvidia A100 - large\n",
      "12 vCPU\n",
      "142 GB\n",
      "Nvidia A100\n",
      "80 GB\n",
      "$2.50\n",
      "Custom\n",
      "on demand\n",
      "on demand\n",
      "on demand\n",
      "on demand\n",
      "on demand\n",
      "ZeroGPU\n",
      "dynamic\n",
      "dynamic\n",
      "Nvidia H200\n",
      "70 GB\n",
      "FREE\n",
      "Spaces Persistent Storage\n",
      "All Spaces get ephemeral storage for free but you can upgrade and add persistent storage at any time.\n",
      "Name\n",
      "Storage\n",
      "Monthly price\n",
      "Small\n",
      "20 GB\n",
      "$5\n",
      "Medium\n",
      "150 GB\n",
      "$25\n",
      "Large\n",
      "1 TB\n",
      "$100\n",
      "Building something cool as a side project? We also offer community GPU grants.\n",
      "Inference Endpoints\n",
      "Starting at $0.033/hour\n",
      "Inference Endpoints (dedicated) offers a secure production solution to easily deploy any ML model on dedicated\n",
      "\t\t\t\t\tand autoscaling infrastructure, right from the HF Hub.\n",
      "→\n",
      "Learn more\n",
      "CPU\n",
      "instances\n",
      "Provider\n",
      "Architecture\n",
      "vCPUs\n",
      "Memory\n",
      "Hourly rate\n",
      "aws\n",
      "Intel Sapphire Rapids\n",
      "1\n",
      "2GB\n",
      "$0.03\n",
      "2\n",
      "4GB\n",
      "$0.07\n",
      "4\n",
      "8GB\n",
      "$0.13\n",
      "8\n",
      "16GB\n",
      "$0.27\n",
      "16\n",
      "32GB\n",
      "$0.54\n",
      "aws\n",
      "Intel Sapphire Rapids (overcommit)\n",
      "16\n",
      "32GB\n",
      "$0.01\n",
      "azure\n",
      "Intel Xeon\n",
      "1\n",
      "2GB\n",
      "$0.06\n",
      "2\n",
      "4GB\n",
      "$0.12\n",
      "4\n",
      "8GB\n",
      "$0.24\n",
      "8\n",
      "16GB\n",
      "$0.48\n",
      "gcp\n",
      "Intel Sapphire Rapids\n",
      "1\n",
      "2GB\n",
      "$0.05\n",
      "2\n",
      "4GB\n",
      "$0.10\n",
      "4\n",
      "8GB\n",
      "$0.20\n",
      "8\n",
      "16GB\n",
      "$0.40\n",
      "Accelerator\n",
      "instances\n",
      "Provider\n",
      "Architecture\n",
      "Topology\n",
      "Accelerator Memory\n",
      "Hourly rate\n",
      "aws\n",
      "Inf2\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tNeuron\n",
      "x1\n",
      "14.5GB\n",
      "$0.75\n",
      "x12\n",
      "760GB\n",
      "$12.00\n",
      "gcp\n",
      "TPU\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tv5e\n",
      "1x1\n",
      "16GB\n",
      "$1.20\n",
      "2x2\n",
      "64GB\n",
      "$4.75\n",
      "2x4\n",
      "128GB\n",
      "$9.50\n",
      "GPU\n",
      "instances\n",
      "Provider\n",
      "Architecture\n",
      "GPUs\n",
      "GPU Memory\n",
      "Hourly rate\n",
      "aws\n",
      "NVIDIA T4\n",
      "1\n",
      "14GB\n",
      "$0.50\n",
      "4\n",
      "56GB\n",
      "$3.00\n",
      "aws\n",
      "NVIDIA L4\n",
      "1\n",
      "24GB\n",
      "$0.80\n",
      "4\n",
      "96GB\n",
      "$3.80\n",
      "aws\n",
      "NVIDIA L40S\n",
      "1\n",
      "48GB\n",
      "$1.80\n",
      "4\n",
      "192GB\n",
      "$8.30\n",
      "8\n",
      "384GB\n",
      "$23.50\n",
      "aws\n",
      "NVIDIA A10G\n",
      "1\n",
      "24GB\n",
      "$1.00\n",
      "4\n",
      "96GB\n",
      "$5.00\n",
      "aws\n",
      "NVIDIA A100\n",
      "1\n",
      "80GB\n",
      "$2.50\n",
      "2\n",
      "160GB\n",
      "$5.00\n",
      "4\n",
      "320GB\n",
      "$10.00\n",
      "8\n",
      "640GB\n",
      "$20.00\n",
      "aws\n",
      "NVIDIA H200\n",
      "1\n",
      "141GB\n",
      "$5.00\n",
      "2\n",
      "282GB\n",
      "$10.00\n",
      "4\n",
      "564GB\n",
      "$20.00\n",
      "8\n",
      "1128GB\n",
      "$40.00\n",
      "gcp\n",
      "NVIDIA T4\n",
      "1\n",
      "16GB\n",
      "$0.50\n",
      "gcp\n",
      "NVIDIA L4\n",
      "1\n",
      "24GB\n",
      "$0.70\n",
      "4\n",
      "96GB\n",
      "$3.80\n",
      "gcp\n",
      "NVIDIA A100\n",
      "1\n",
      "80GB\n",
      "$3.60\n",
      "2\n",
      "160GB\n",
      "$7.20\n",
      "4\n",
      "320GB\n",
      "$14.40\n",
      "8\n",
      "640GB\n",
      "$28.80\n",
      "gcp\n",
      "NVIDIA H100\n",
      "1\n",
      "80GB\n",
      "$10.00\n",
      "2\n",
      "160GB\n",
      "$20.00\n",
      "4\n",
      "320GB\n",
      "$40.00\n",
      "8\n",
      "640GB\n",
      "$80.00\n",
      "PRO Account\n",
      "PRO\n",
      "A monthly subscription to access powerful features.\n",
      "→\n",
      "Get PRO\n",
      "($9/month)\n",
      "Inference Providers\n",
      ": Get 20× included inference credits\n",
      "ZeroGPU\n",
      ": Get 8× usage quota and highest priority in queues\n",
      "Spaces Hosting\n",
      ": Create ZeroGPU Spaces with H200 hardware\n",
      "Spaces Dev Mode\n",
      ": Fast iterations via SSH/VS Code for Spaces\n",
      "Dataset Viewer\n",
      ": Activate and use it on private datasets\n",
      "Blog Articles\n",
      ": Publish articles on your HF profile\n",
      "Features Preview\n",
      ": Get early access to upcoming\n",
      "\t\t\t\t\t\t\t\t\t\tfeatures\n",
      "PRO\n",
      "Badge\n",
      ":\n",
      "\t\t\t\t\t\t\t\t\t\tShow your support on your profile\n",
      "System theme\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Changelog\n",
      "Inference Endpoints\n",
      "HuggingChat\n",
      "Company\n",
      "About\n",
      "Brand assets\n",
      "Terms of service\n",
      "Privacy\n",
      "Jobs\n",
      "Press\n",
      "Resources\n",
      "Learn\n",
      "Documentation\n",
      "Blog\n",
      "Forum\n",
      "Service Status\n",
      "Social\n",
      "GitHub\n",
      "Twitter\n",
      "LinkedIn\n",
      "Discord\n",
      "\n",
      "\n",
      "\n",
      "blog page\n",
      "Webpage Title:\n",
      "Hugging Face – Blog\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Blog, Articles, and discussions\n",
      "New Article\n",
      "Everything\n",
      "community\n",
      "guide\n",
      "open source collab\n",
      "partnerships\n",
      "research\n",
      "NLP\n",
      "Audio\n",
      "CV\n",
      "RL\n",
      "ethics\n",
      "Diffusion\n",
      "Game Development\n",
      "RLHF\n",
      "Leaderboard\n",
      "Case Studies\n",
      "LeRobot\n",
      "Inference Providers\n",
      "Generate Images with Claude and Hugging Face\n",
      "By\n",
      "evalstate\n",
      "August 19, 2025\n",
      "•\n",
      "12\n",
      "Community Articles\n",
      "view all\n",
      "NVIDIA Releases 3 Million Sample Dataset for OCR, Visual Question Answering, and Captioning Tasks\n",
      "By\n",
      "nvidia\n",
      "and 4 others\n",
      "•\n",
      "10 days ago\n",
      "•\n",
      "63\n",
      "How To Build a News Agent with GPT-OSS, Hugging Face Inference & Gradio\n",
      "By\n",
      "fdaudens\n",
      "•\n",
      "7 days ago\n",
      "•\n",
      "19\n",
      "Supercharge Edge AI With High‑Accuracy Reasoning Using NVIDIA Nemotron Nano  2 9B\n",
      "By\n",
      "nvidia\n",
      "and 9 others\n",
      "•\n",
      "3 days ago\n",
      "•\n",
      "14\n",
      "ChatML vs Harmony: Understanding the new Format from OpenAI 🔍\n",
      "By\n",
      "kuotient\n",
      "•\n",
      "12 days ago\n",
      "•\n",
      "25\n",
      "Old Maps, New Terrain: Updating Labour Taxonomies for the AI Era\n",
      "By\n",
      "frimelle\n",
      "and 1 other\n",
      "•\n",
      "1 day ago\n",
      "•\n",
      "12\n",
      "Uncensor any LLM with abliteration\n",
      "By\n",
      "mlabonne\n",
      "•\n",
      "Jun 13, 2024\n",
      "•\n",
      "656\n",
      "What’s MXFP4? The 4-Bit Secret Powering OpenAI’s GPT‑OSS Models on Modest Hardware\n",
      "By\n",
      "RakshitAralimatti\n",
      "•\n",
      "13 days ago\n",
      "•\n",
      "15\n",
      "Kimina-Prover-RL\n",
      "By\n",
      "AI-MO\n",
      "and 18 others\n",
      "•\n",
      "7 days ago\n",
      "•\n",
      "8\n",
      "Code a simple RAG from scratch\n",
      "By\n",
      "ngxson\n",
      "•\n",
      "Oct 29, 2024\n",
      "•\n",
      "159\n",
      "NVIDIA Releases 6 Million Multi-Lingual Reasoning Dataset\n",
      "By\n",
      "nvidia\n",
      "and 4 others\n",
      "•\n",
      "about 18 hours ago\n",
      "•\n",
      "7\n",
      "RynnVLA-001: Using Human Demonstrations to Improve Robot Manipulation\n",
      "By\n",
      "Alibaba-DAMO-Academy\n",
      "and 9 others\n",
      "•\n",
      "10 days ago\n",
      "•\n",
      "25\n",
      "RynnEC: Bringing MLLMs into Embodied World\n",
      "By\n",
      "Alibaba-DAMO-Academy\n",
      "and 6 others\n",
      "•\n",
      "7 days ago\n",
      "•\n",
      "6\n",
      "AutoBench Third Run: Revolutionizing LLM Evaluation with Record-Breaking Scale, Accuracy, and a New Home at autobench.org\n",
      "By\n",
      "PeterKruger\n",
      "•\n",
      "1 day ago\n",
      "•\n",
      "6\n",
      "Introducing Pivotal Token Search (PTS): Targeting Critical Decision Points in LLM Training\n",
      "By\n",
      "codelion\n",
      "•\n",
      "May 17\n",
      "•\n",
      "9\n",
      "DeepSeek-R1 Dissection: Understanding PPO & GRPO Without Any Prior Reinforcement Learning Knowledge\n",
      "By\n",
      "NormalUhr\n",
      "•\n",
      "Feb 7\n",
      "•\n",
      "209\n",
      "From GRPO to DAPO and GSPO: What, Why, and How\n",
      "By\n",
      "NormalUhr\n",
      "•\n",
      "12 days ago\n",
      "•\n",
      "12\n",
      "Introduction to State Space Models (SSM)\n",
      "By\n",
      "lbourdois\n",
      "•\n",
      "Jul 19, 2024\n",
      "•\n",
      "163\n",
      "KV Caching Explained: Optimizing Transformer Inference Efficiency\n",
      "By\n",
      "not-lain\n",
      "•\n",
      "Jan 30\n",
      "•\n",
      "115\n",
      "Post-Training Isaac GR00T N1.5 for LeRobot SO-101 Arm\n",
      "By\n",
      "nvidia\n",
      "and 5 others\n",
      "•\n",
      "Jun 11\n",
      "•\n",
      "81\n",
      "How to Run a Hugging Face Model in JAX (Part 1)\n",
      "By\n",
      "qihqi\n",
      "•\n",
      "Jul 20\n",
      "•\n",
      "22\n",
      "From Zero to GPU: A Guide to Building and Scaling Production-Ready CUDA Kernels\n",
      "By\n",
      "drbh\n",
      "August 18, 2025\n",
      "•\n",
      "32\n",
      "MCP for Research: How to Connect AI to Research Tools\n",
      "By\n",
      "dylanebert\n",
      "August 18, 2025\n",
      "•\n",
      "28\n",
      "TextQuests: How Good are LLMs at Text-Based Video Games?\n",
      "By\n",
      "justinphan3110\n",
      "August 12, 2025\n",
      "guest\n",
      "•\n",
      "25\n",
      "Introducing AI Sheets: a tool to work with datasets using open AI models!\n",
      "By\n",
      "dvilasuero\n",
      "August 8, 2025\n",
      "•\n",
      "64\n",
      "Accelerate ND-Parallel: A Guide to Efficient Multi-GPU Training\n",
      "By\n",
      "siro1\n",
      "August 8, 2025\n",
      "•\n",
      "50\n",
      "🇵🇭 FilBench - Can LLMs Understand and Generate Filipino?\n",
      "By\n",
      "ljvmiranda921\n",
      "August 12, 2025\n",
      "•\n",
      "13\n",
      "Vision Language Model Alignment in TRL ⚡️\n",
      "By\n",
      "sergiopaniego\n",
      "August 7, 2025\n",
      "•\n",
      "69\n",
      "Welcome GPT OSS, the new open-source model family from OpenAI!\n",
      "By\n",
      "reach-vb\n",
      "August 5, 2025\n",
      "•\n",
      "469\n",
      "Build an AI Shopping Assistant with Gradio MCP Servers\n",
      "By\n",
      "freddyaboulton\n",
      "July 31, 2025\n",
      "•\n",
      "50\n",
      "Introducing Trackio: A Lightweight Experiment Tracking Library from Hugging Face\n",
      "By\n",
      "abidlabs\n",
      "July 29, 2025\n",
      "•\n",
      "156\n",
      "Say hello to `hf`: a faster, friendlier Hugging Face CLI ✨\n",
      "By\n",
      "Wauplin\n",
      "July 25, 2025\n",
      "•\n",
      "77\n",
      "Parquet Content-Defined Chunking\n",
      "By\n",
      "kszucs\n",
      "July 25, 2025\n",
      "•\n",
      "60\n",
      "TimeScope: How Long Can Your Video Large Multimodal Model Go?\n",
      "By\n",
      "orrzohar\n",
      "July 23, 2025\n",
      "•\n",
      "38\n",
      "Fast LoRA inference for Flux with Diffusers and PEFT\n",
      "By\n",
      "sayakpaul\n",
      "July 23, 2025\n",
      "•\n",
      "45\n",
      "Previous\n",
      "1\n",
      "2\n",
      "3\n",
      "...\n",
      "45\n",
      "Next\n",
      "Community Articles\n",
      "Sort: \n",
      "\t\tTrending\n",
      "NVIDIA Releases 3 Million Sample Dataset for OCR, Visual Question Answering, and Captioning Tasks\n",
      "By\n",
      "nvidia\n",
      "and 4 others\n",
      "•\n",
      "10 days ago\n",
      "•\n",
      "63\n",
      "How To Build a News Agent with GPT-OSS, Hugging Face Inference & Gradio\n",
      "By\n",
      "fdaudens\n",
      "•\n",
      "7 days ago\n",
      "•\n",
      "19\n",
      "Supercharge Edge AI With High‑Accuracy Reasoning Using NVIDIA Nemotron Nano  2 9B\n",
      "By\n",
      "nvidia\n",
      "and 9 others\n",
      "•\n",
      "3 days ago\n",
      "•\n",
      "14\n",
      "ChatML vs Harmony: Understanding the new Format from OpenAI 🔍\n",
      "By\n",
      "kuotient\n",
      "•\n",
      "12 days ago\n",
      "•\n",
      "25\n",
      "Old Maps, New Terrain: Updating Labour Taxonomies for the AI Era\n",
      "By\n",
      "frimelle\n",
      "and 1 other\n",
      "•\n",
      "1 day ago\n",
      "•\n",
      "12\n",
      "Uncensor any LLM with abliteration\n",
      "By\n",
      "mlabonne\n",
      "•\n",
      "Jun 13, 2024\n",
      "•\n",
      "656\n",
      "What’s MXFP4? The 4-Bit Secret Powering OpenAI’s GPT‑OSS Models on Modest Hardware\n",
      "By\n",
      "RakshitAralimatti\n",
      "•\n",
      "13 days ago\n",
      "•\n",
      "15\n",
      "Kimina-Prover-RL\n",
      "By\n",
      "AI-MO\n",
      "and 18 others\n",
      "•\n",
      "7 days ago\n",
      "•\n",
      "8\n",
      "Code a simple RAG from scratch\n",
      "By\n",
      "ngxson\n",
      "•\n",
      "Oct 29, 2024\n",
      "•\n",
      "159\n",
      "NVIDIA Releases 6 Million Multi-Lingual Reasoning Dataset\n",
      "By\n",
      "nvidia\n",
      "and 4 others\n",
      "•\n",
      "about 18 hours ago\n",
      "•\n",
      "7\n",
      "RynnVLA-001: Using Human Demonstrations to Improve Robot Manipulation\n",
      "By\n",
      "Alibaba-DAMO-Academy\n",
      "and 9 others\n",
      "•\n",
      "10 days ago\n",
      "•\n",
      "25\n",
      "RynnEC: Bringing MLLMs into Embodied World\n",
      "By\n",
      "Alibaba-DAMO-Academy\n",
      "and 6 others\n",
      "•\n",
      "7 days ago\n",
      "•\n",
      "6\n",
      "AutoBench Third Run: Revolutionizing LLM Evaluation with Record-Breaking Scale, Accuracy, and a New Home at autobench.org\n",
      "By\n",
      "PeterKruger\n",
      "•\n",
      "1 day ago\n",
      "•\n",
      "6\n",
      "Introducing Pivotal Token Search (PTS): Targeting Critical Decision Points in LLM Training\n",
      "By\n",
      "codelion\n",
      "•\n",
      "May 17\n",
      "•\n",
      "9\n",
      "DeepSeek-R1 Dissection: Understanding PPO & GRPO Without Any Prior Reinforcement Learning Knowledge\n",
      "By\n",
      "NormalUhr\n",
      "•\n",
      "Feb 7\n",
      "•\n",
      "209\n",
      "From GRPO to DAPO and GSPO: What, Why, and How\n",
      "By\n",
      "NormalUhr\n",
      "•\n",
      "12 days ago\n",
      "•\n",
      "12\n",
      "Introduction to State Space Models (SSM)\n",
      "By\n",
      "lbourdois\n",
      "•\n",
      "Jul 19, 2024\n",
      "•\n",
      "163\n",
      "KV Caching Explained: Optimizing Transformer Inference Efficiency\n",
      "By\n",
      "not-lain\n",
      "•\n",
      "Jan 30\n",
      "•\n",
      "115\n",
      "Post-Training Isaac GR00T N1.5 for LeRobot SO-101 Arm\n",
      "By\n",
      "nvidia\n",
      "and 5 others\n",
      "•\n",
      "Jun 11\n",
      "•\n",
      "81\n",
      "How to Run a Hugging Face Model in JAX (Part 1)\n",
      "By\n",
      "qihqi\n",
      "•\n",
      "Jul 20\n",
      "•\n",
      "22\n",
      "View all\n",
      "System theme\n",
      "Company\n",
      "TOS\n",
      "Privacy\n",
      "About\n",
      "Jobs\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Pricing\n",
      "Docs\n",
      "\n",
      "\n",
      "\n",
      "documentation page\n",
      "Webpage Title:\n",
      "Hugging Face - Documentation\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Documentation\n",
      "Hub & Client Libraries\n",
      "Hub\n",
      "Host Git-based models, datasets, and Spaces on the HF Hub\n",
      "Hub Python Library\n",
      "Python client to interact with the Hugging Face Hub\n",
      "Huggingface.js\n",
      "JavaScript libraries for Hugging Face with built-in TS types\n",
      "Tasks\n",
      "Explore demos, models, and datasets for any ML tasks\n",
      "Dataset viewer\n",
      "API for metadata, stats, and content of HF Hub datasets\n",
      "Deployment & Inference\n",
      "Inference Providers\n",
      "Call 200k+ models hosted by our 10+ Inference partners\n",
      "Inference Endpoints (dedicated)\n",
      "Deploy models on dedicated & fully managed infrastructure on HF\n",
      "Deploying on AWS\n",
      "Train/deploy models from Hugging Face to AWS with DLCs\n",
      "Text Generation Inference\n",
      "Serve language models with TGI optimized toolkit\n",
      "Text Embeddings Inference\n",
      "Serve embeddings models with TEI optimized toolkit\n",
      "Microsoft Azure\n",
      "Deploy Hugging Face models on Microsoft Azure\n",
      "Core ML Libraries\n",
      "Transformers\n",
      "State-of-the-art AI models for PyTorch\n",
      "Diffusers\n",
      "State-of-the-art Diffusion models in PyTorch\n",
      "Datasets\n",
      "Access & share datasets for any ML tasks\n",
      "Transformers.js\n",
      "State-of-the-art ML running directly in your browser\n",
      "Tokenizers\n",
      "Fast tokenizers optimized for research & production\n",
      "Evaluate\n",
      "Evaluate and compare models performance\n",
      "timm\n",
      "State-of-the-art vision models: layers, optimizers, and utilities\n",
      "Sentence Transformers\n",
      "Embeddings, Retrieval, and Reranking\n",
      "Training & Optimization\n",
      "PEFT\n",
      "Parameter-efficient finetuning for large language models\n",
      "Accelerate\n",
      "Train PyTorch models with multi-GPU, TPU, mixed precision\n",
      "Optimum\n",
      "Optimize HF Transformers for faster training/inference\n",
      "AWS Trainium & Inferentia\n",
      "Train/deploy Transformers/Diffusers on AWS\n",
      "TRL\n",
      "Train transformers LMs with reinforcement learning\n",
      "Safetensors\n",
      "Safe way to store/distribute neural network weights\n",
      "Bitsandbytes\n",
      "Optimize and quantize models with bitsandbytes\n",
      "Lighteval\n",
      "All-in-one toolkit to evaluate LLMs across multiple backends\n",
      "Collaboration & Extras\n",
      "Gradio\n",
      "Build ML demos and web apps with a few lines of Python\n",
      "smolagents\n",
      "Smol library to build great agents in Python\n",
      "LeRobot\n",
      "Making AI for Robotics more accessible with end-to-end learning\n",
      "AutoTrain\n",
      "AutoTrain API and UI for seamless model training\n",
      "Chat UI\n",
      "Open source chat frontend powering HuggingChat\n",
      "Leaderboards\n",
      "Create custom Leaderboards on Hugging Face\n",
      "Argilla\n",
      "Collaboration tool for building high-quality datasets\n",
      "Distilabel\n",
      "Framework for synthetic data generation and AI feedback\n",
      "Community\n",
      "Blog\n",
      "Learn\n",
      "Discord\n",
      "Forum\n",
      "Github\n",
      "System theme\n",
      "Company\n",
      "TOS\n",
      "Privacy\n",
      "About\n",
      "Jobs\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Pricing\n",
      "Docs\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_all_details(\"https://huggingface.co\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b863a55-f86c-4e3f-8a79-94e24c1a8cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
    "and creates a short brochure about the company for prospective customers, investors and recruits. Respond in markdown.\\\n",
    "Include details of company culture, customers and careers/jobs if you have the information.\"\n",
    "\n",
    "# Or uncomment the lines below for a more humorous brochure - this demonstrates how easy it is to incorporate 'tone':\n",
    "\n",
    "# system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
    "# and creates a short humorous, entertaining, jokey brochure about the company for prospective customers, investors and recruits. Respond in markdown.\\\n",
    "# Include details of company culture, customers and careers/jobs if you have the information.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ab83d92-d36b-4ce0-8bcc-5bb4c2f8ff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brochure_user_prompt(company_name, url):\n",
    "    user_prompt = f\"You are looking at a company called: {company_name}\\n\"\n",
    "    user_prompt += f\"Here are the contents of its landing page and other relevant pages; use this information to build a short brochure of the company in markdown.\\n\"\n",
    "    user_prompt += get_all_details(url)\n",
    "    user_prompt = user_prompt[:5_000] # Truncate if more than 5,000 characters\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd909e0b-1312-4ce2-a553-821e795d7572",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_brochure_user_prompt(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e44de579-4a1a-4e6a-a510-20ea3e4b8d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_brochure(company_name, url):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "          ],\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e093444a-9407-42ae-924a-145730591a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links: {'links': [{'type': 'about page', 'url': 'https://huggingface.co'}, {'type': 'careers page', 'url': 'https://apply.workable.com/huggingface/'}, {'type': 'enterprise page', 'url': 'https://huggingface.co/enterprise'}, {'type': 'pricing page', 'url': 'https://huggingface.co/pricing'}, {'type': 'blog page', 'url': 'https://huggingface.co/blog'}, {'type': 'github page', 'url': 'https://github.com/huggingface'}, {'type': 'twitter page', 'url': 'https://twitter.com/huggingface'}, {'type': 'linkedin page', 'url': 'https://www.linkedin.com/company/huggingface/'}]}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```markdown\n",
       "# Hugging Face: The AI Community Building the Future\n",
       "\n",
       "---\n",
       "\n",
       "## About Us\n",
       "\n",
       "Hugging Face is a dynamic platform dedicated to fostering community-driven innovation in artificial intelligence. Our mission is to create a collaborative environment where machine learning enthusiasts, researchers, and enterprises can engage, share, and advance AI technologies.\n",
       "\n",
       "### Key Features:\n",
       "- **Collaborative Hub**: With over 1 million AI models and datasets, Hugging Face is the primary location for the machine learning community to co-create and experiment.\n",
       "- **Diverse Modalities**: Support for text, image, video, audio, and 3D applications, allowing users to build and share across multiple AI domains.\n",
       "- **Open Source Commitment**: We heavily invest in open-source projects, providing tools like **Transformers** and **Diffusers** that empower developers to build cutting-edge AI solutions.\n",
       "\n",
       "---\n",
       "\n",
       "## Our Community\n",
       "\n",
       "Hugging Face brings together over **50,000 organizations**, including notable enterprises like Meta, Google, and Microsoft, all of whom utilize our platform to push the frontiers of AI. The collaborative atmosphere fosters a rich exchange of ideas and tools among individuals and institutions alike.\n",
       "\n",
       "### Trending Models:\n",
       "1. **Qwen/Qwen-Image-Edit** – 16.8k uses\n",
       "2. **DeepSeek-V3.1-Base** – 5.68k uses\n",
       "3. **gemma-3-270m by Google** – 49.1k uses\n",
       "\n",
       "### Engage in Your Interests:\n",
       "- **Explore AI Apps**: Access and contribute to hundreds of applications.\n",
       "- **Datasets Library**: Browse and utilize over 250,000 datasets for various ML tasks.\n",
       "\n",
       "---\n",
       "\n",
       "## Career Opportunities\n",
       "\n",
       "At Hugging Face, we believe our strongest asset is our team. We are always looking for passionate individuals who are eager to innovate in AI. Our culture promotes flexibility, creativity, and growth within a supportive team atmosphere.\n",
       "\n",
       "### Why Work With Us?\n",
       "- **Innovative Environment**: Work at the forefront of ML and AI technology.\n",
       "- **Flexible Work Culture**: Embrace the ability to work where you are most productive.\n",
       "- **Diversity and Inclusion**: We celebrate diversity and are committed to creating an inclusive workplace.\n",
       "\n",
       "### Current Openings:\n",
       "- Data Scientists\n",
       "- ML Engineers\n",
       "- Community Managers\n",
       "- Product Designers\n",
       "\n",
       "---\n",
       "\n",
       "## Join Us\n",
       "\n",
       "Whether you are a prospective customer looking to leverage AI technologies, an investor interested in the future of machine learning, or a talented individual ready to take your career to the next level, Hugging Face welcomes you to be part of our transformative journey.\n",
       "\n",
       "**Discover more at** [huggingface.co](https://huggingface.co)\n",
       "\n",
       "--- \n",
       "```\n",
       "This brochure effectively covers core aspects of Hugging Face, including its purpose, community involvement, and career opportunities, in an attractive and informative format."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_brochure(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eaaab7-0b47-4b29-82d4-75d474ad8d18",
   "metadata": {},
   "source": [
    "## Finally - a minor improvement\n",
    "\n",
    "With a small adjustment, we can change this so that the results stream back from OpenAI,\n",
    "with the familiar typewriter animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51db0e49-f261-4137-aabe-92dd601f7725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_brochure(company_name, url):\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "          ],\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56bf0ae3-ee9d-4a72-9cd6-edcac67ceb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links: {'links': [{'type': 'about page', 'url': 'https://huggingface.co/huggingface'}, {'type': 'careers page', 'url': 'https://apply.workable.com/huggingface/'}, {'type': 'enterprise page', 'url': 'https://huggingface.co/enterprise'}, {'type': 'pricing page', 'url': 'https://huggingface.co/pricing'}, {'type': 'blog page', 'url': 'https://huggingface.co/blog'}, {'type': 'documentation page', 'url': 'https://huggingface.co/docs'}]}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Hugging Face Company Brochure\n",
       "\n",
       "---\n",
       "\n",
       "## **About Us**\n",
       "\n",
       "### **Hugging Face**\n",
       "Welcome to Hugging Face, a thriving AI community dedicated to building the future of machine learning. Our mission is to foster collaboration among developers, researchers, and organizations worldwide, all while pushing the boundaries of AI technology.\n",
       "\n",
       "With over 50,000 organizations, including industry giants like Google, Microsoft, and Amazon, leveraging our tools, we are at the forefront of AI innovation.\n",
       "\n",
       "## **What We Offer**\n",
       "\n",
       "- **Models:** Access a diverse range of over 1 million AI models spanning various domains, including text, image, video, and audio.\n",
       "  \n",
       "- **Datasets:** Discover and share over 250,000 datasets to elevate your machine learning projects.\n",
       "\n",
       "- **Spaces:** Collaborate on applications and prototypes using our dedicated environments to test and iterate your AI systems.\n",
       "\n",
       "- **Enterprise Solutions:** For teams looking for power and security, we offer enterprise-grade solutions with priority support, audit logs, and more.\n",
       "\n",
       "## **Our Community**\n",
       "\n",
       "At Hugging Face, collaboration is key! We support an active open-source community that drives advancements in machine learning. You can explore trending models such as:\n",
       "\n",
       "- **Qwen Image Edit**\n",
       "- **DeepSeek-V3.1**\n",
       "- **Gemma-3-270m**\n",
       "\n",
       "Join us in creating, discovering, and improving machine learning experiences! We believe in the power of community and open-source development, with a rich library of tools available to optimize your ML workflow.\n",
       "\n",
       "## **Company Culture**\n",
       "\n",
       "At Hugging Face, we cultivate an inclusive, innovative, and collaborative work environment. Our team is passionate about technology and believes in the importance of community-driven development. This culture fosters individual growth while encouraging teamwork to solve complex problems and enhance AI capabilities.\n",
       "\n",
       "## **Careers with Us**\n",
       "\n",
       "Are you ready to build the future of AI? We are always on the lookout for talent that shares our vision! Join a team that values creativity, diversity, and impact:\n",
       "\n",
       "- **Career Opportunities:** Explore current job openings across various roles from machine learning engineers to software developers.\n",
       "- **Remote Friendly:** We offer flexible work arrangements that value work-life balance.\n",
       "\n",
       "## **Get Involved**\n",
       "\n",
       "1. **Explore Our Tools:** Sign up to start using our platform and tailor it for your needs.\n",
       "2. **Join the Community:** Engage with like-minded individuals on our Discord and GitHub channels.\n",
       "3. **Stay Updated:** Follow us on social media and our blog for the latest in AI and machine learning advancements!\n",
       "\n",
       "---\n",
       "\n",
       "Discover the future of AI with Hugging Face—your partner in creating the next generation of intelligent technologies. Visit us at [Hugging Face](https://huggingface.co) and be part of our community!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stream_brochure(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fdb3f8d8-a3eb-41c8-b1aa-9f60686a653b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links: {'links': [{'type': 'about page', 'url': 'https://huggingface.co/huggingface'}, {'type': 'careers page', 'url': 'https://apply.workable.com/huggingface/'}, {'type': 'enterprise page', 'url': 'https://huggingface.co/enterprise'}, {'type': 'pricing page', 'url': 'https://huggingface.co/pricing'}, {'type': 'blog page', 'url': 'https://huggingface.co/blog'}, {'type': 'models page', 'url': 'https://huggingface.co/models'}, {'type': 'datasets page', 'url': 'https://huggingface.co/datasets'}, {'type': 'spaces page', 'url': 'https://huggingface.co/spaces'}, {'type': 'docs page', 'url': 'https://huggingface.co/docs'}]}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Hugging Face Company Brochure\n",
       "\n",
       "## Welcome to Hugging Face\n",
       "### \"The AI community building the future.\"\n",
       "\n",
       "At Hugging Face, we are at the forefront of the artificial intelligence revolution, providing a collaborative platform where the machine learning community can thrive. Our mission is to create a space for developers, researchers, and enthusiasts to create, share, and deploy state-of-the-art machine learning models and datasets.\n",
       "\n",
       "---\n",
       "\n",
       "## What We Offer\n",
       "\n",
       "### Explore AI Models\n",
       "With over **1 million models** to choose from, professionals can easily browse, create, and enhance their projects using cutting-edge AI technologies. Recent trending models include:\n",
       "- **Qwen/Qwen-Image-Edit**: Image editing based on user instructions\n",
       "- **DeepSeek-V3.1**: An adaptive AI model for various applications\n",
       "- **Google/Gemma-3**: Advanced natural language models\n",
       "\n",
       "### Datasets & Applications\n",
       "The platform hosts **over 250,000 datasets** and **400,000 applications**, making it an invaluable resource for any AI project. Users can access and share datasets designed for diverse machine learning tasks.\n",
       "\n",
       "### Paid Solutions\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RemoteProtocolError",
     "evalue": "peer closed connection without sending complete message body (incomplete chunked read)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRemoteProtocolError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Personal\\AI_ML\\llm_engineering\\venv\\Lib\\site-packages\\httpx\\_transports\\default.py:101\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Personal\\AI_ML\\llm_engineering\\venv\\Lib\\site-packages\\httpx\\_transports\\default.py:127\u001b[39m, in \u001b[36mResponseStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_httpcore_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Personal\\AI_ML\\llm_engineering\\venv\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:407\u001b[39m, in \u001b[36mPoolByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    406\u001b[39m \u001b[38;5;28mself\u001b[39m.close()\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Personal\\AI_ML\\llm_engineering\\venv\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:403\u001b[39m, in \u001b[36mPoolByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Personal\\AI_ML\\llm_engineering\\venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:342\u001b[39m, in \u001b[36mHTTP11ConnectionByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    341\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Personal\\AI_ML\\llm_engineering\\venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:334\u001b[39m, in \u001b[36mHTTP11ConnectionByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mreceive_response_body\u001b[39m\u001b[33m\"\u001b[39m, logger, \u001b[38;5;28mself\u001b[39m._request, kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Personal\\AI_ML\\llm_engineering\\venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:203\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_body\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Data):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Personal\\AI_ML\\llm_engineering\\venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:213\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions({h11.RemoteProtocolError: RemoteProtocolError}):\n\u001b[32m    214\u001b[39m         event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\contextlib.py:158\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    160\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    161\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Personal\\AI_ML\\llm_engineering\\venv\\Lib\\site-packages\\httpcore\\_exceptions.py:14\u001b[39m, in \u001b[36mmap_exceptions\u001b[39m\u001b[34m(map)\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mRemoteProtocolError\u001b[39m: peer closed connection without sending complete message body (incomplete chunked read)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRemoteProtocolError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Try changing the system prompt to the humorous version when you make the Brochure for Hugging Face:\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mstream_brochure\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHuggingFace\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhttps://huggingface.co\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mstream_brochure\u001b[39m\u001b[34m(company_name, url)\u001b[39m\n\u001b[32m     11\u001b[39m response = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     12\u001b[39m display_handle = display(Markdown(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m), display_id=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchoices\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m```\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmarkdown\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Personal\\AI_ML\\llm_engineering\\venv\\Lib\\site-packages\\openai\\_streaming.py:46\u001b[39m, in \u001b[36mStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterator[_T]:\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Personal\\AI_ML\\llm_engineering\\venv\\Lib\\site-packages\\openai\\_streaming.py:58\u001b[39m, in \u001b[36mStream.__stream__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     55\u001b[39m process_data = \u001b[38;5;28mself\u001b[39m._client._process_response_data\n\u001b[32m     56\u001b[39m iterator = \u001b[38;5;28mself\u001b[39m._iter_events()\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msse\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstartswith\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m[DONE]\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mbreak\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Personal\\AI_ML\\llm_engineering\\venv\\Lib\\site-packages\\openai\\_streaming.py:50\u001b[39m, in \u001b[36mStream._iter_events\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_iter_events\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterator[ServerSentEvent]:\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decoder.iter_bytes(\u001b[38;5;28mself\u001b[39m.response.iter_bytes())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Personal\\AI_ML\\llm_engineering\\venv\\Lib\\site-packages\\openai\\_streaming.py:280\u001b[39m, in \u001b[36mSSEDecoder.iter_bytes\u001b[39m\u001b[34m(self, iterator)\u001b[39m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34miter_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, iterator: Iterator[\u001b[38;5;28mbytes\u001b[39m]) -> Iterator[ServerSentEvent]:\n\u001b[32m    279\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Given an iterator that yields raw binary data, iterate over it & yield every event encountered\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m280\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iter_chunks\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Split before decoding so splitlines() only uses \\r and \\n\u001b[39;49;00m\n\u001b[32m    282\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_line\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitlines\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m            \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_line\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Personal\\AI_ML\\llm_engineering\\venv\\Lib\\site-packages\\openai\\_streaming.py:291\u001b[39m, in \u001b[36mSSEDecoder._iter_chunks\u001b[39m\u001b[34m(self, iterator)\u001b[39m\n\u001b[32m    289\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Given an iterator that yields raw binary data, iterate over it and yield individual SSE chunks\"\"\"\u001b[39;00m\n\u001b[32m    290\u001b[39m data = \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m291\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitlines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeepends\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    293\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Personal\\AI_ML\\llm_engineering\\venv\\Lib\\site-packages\\httpx\\_models.py:897\u001b[39m, in \u001b[36mResponse.iter_bytes\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    895\u001b[39m chunker = ByteChunker(chunk_size=chunk_size)\n\u001b[32m    896\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m897\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Personal\\AI_ML\\llm_engineering\\venv\\Lib\\site-packages\\httpx\\_models.py:951\u001b[39m, in \u001b[36mResponse.iter_raw\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    948\u001b[39m chunker = ByteChunker(chunk_size=chunk_size)\n\u001b[32m    950\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m951\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_num_bytes_downloaded\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Personal\\AI_ML\\llm_engineering\\venv\\Lib\\site-packages\\httpx\\_client.py:153\u001b[39m, in \u001b[36mBoundSyncStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Personal\\AI_ML\\llm_engineering\\venv\\Lib\\site-packages\\httpx\\_transports\\default.py:126\u001b[39m, in \u001b[36mResponseStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m    127\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._httpcore_stream:\n\u001b[32m    128\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m part\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\contextlib.py:158\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    156\u001b[39m     value = typ()\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    160\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    161\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Personal\\AI_ML\\llm_engineering\\venv\\Lib\\site-packages\\httpx\\_transports\\default.py:118\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    117\u001b[39m message = \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mRemoteProtocolError\u001b[39m: peer closed connection without sending complete message body (incomplete chunked read)"
     ]
    }
   ],
   "source": [
    "# Try changing the system prompt to the humorous version when you make the Brochure for Hugging Face:\n",
    "\n",
    "stream_brochure(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27bf9e0-665f-4645-b66b-9725e2a959b5",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../business.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#181;\">Business applications</h2>\n",
    "            <span style=\"color:#181;\">In this exercise we extended the Day 1 code to make multiple LLM calls, and generate a document.\n",
    "\n",
    "This is perhaps the first example of Agentic AI design patterns, as we combined multiple calls to LLMs. This will feature more in Week 2, and then we will return to Agentic AI in a big way in Week 8 when we build a fully autonomous Agent solution.\n",
    "\n",
    "Generating content in this way is one of the very most common Use Cases. As with summarization, this can be applied to any business vertical. Write marketing content, generate a product tutorial from a spec, create personalized email content, and so much more. Explore how you can apply content generation to your business, and try making yourself a proof-of-concept prototype. See what other students have done in the community-contributions folder -- so many valuable projects -- it's wild!</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b2454b-8ef8-4b5c-b928-053a15e0d553",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#900;\">Before you move to Week 2 (which is tons of fun)</h2>\n",
    "            <span style=\"color:#900;\">Please see the week1 EXERCISE notebook for your challenge for the end of week 1. This will give you some essential practice working with Frontier APIs, and prepare you well for Week 2.</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b64f0f-7d33-4493-985a-033d06e8db08",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">A reminder on 3 useful resources</h2>\n",
    "            <span style=\"color:#f71;\">1. The resources for the course are available <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">here.</a><br/>\n",
    "            2. I'm on LinkedIn <a href=\"https://www.linkedin.com/in/eddonner/\">here</a> and I love connecting with people taking the course!<br/>\n",
    "            3. I'm trying out X/Twitter and I'm at <a href=\"https://x.com/edwarddonner\">@edwarddonner<a> and hoping people will teach me how it's done..  \n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f48e42e-fa7a-495f-a5d4-26bfc24d60b6",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../thankyou.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#090;\">Finally! I have a special request for you</h2>\n",
    "            <span style=\"color:#090;\">\n",
    "                My editor tells me that it makes a MASSIVE difference when students rate this course on Udemy - it's one of the main ways that Udemy decides whether to show it to others. If you're able to take a minute to rate this, I'd be so very grateful! And regardless - always please reach out to me at ed@edwarddonner.com if I can help at any point.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d3e1a1-ba54-4907-97c5-30f89a24775b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.12.7"
=======
   "version": "3.11.13"
>>>>>>> 804ac62e781fa0fbb32cd2a0e95343d71b08d6f9
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
